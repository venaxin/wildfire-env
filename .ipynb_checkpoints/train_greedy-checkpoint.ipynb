{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b85c2-486a-4c23-85f1-175a987fc627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’° Starting COMPETITIVE/GREEDY Training...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 417      |\n",
      "|    ep_rew_mean     | -491     |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 468         |\n",
      "|    ep_rew_mean          | -477        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020205367 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 475         |\n",
      "|    ep_rew_mean          | -449        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023263928 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 0.000161    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 496         |\n",
      "|    ep_rew_mean          | -434        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021404594 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.00055     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | -414        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026500646 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.000512    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 579         |\n",
      "|    ep_rew_mean          | -367        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009298765 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.000364    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 579         |\n",
      "|    ep_rew_mean          | -334        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1062        |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008672926 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000676   |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 574         |\n",
      "|    ep_rew_mean          | -299        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1209        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016286373 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 593         |\n",
      "|    ep_rew_mean          | -281        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1343        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010623453 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 580         |\n",
      "|    ep_rew_mean          | -260        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1480        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013739755 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 7.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | -238        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1625        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012607407 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | -220        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1775        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010646148 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    value_loss           | 6.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | -208        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1908        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008618341 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 4.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 593         |\n",
      "|    ep_rew_mean          | -196        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 2039        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011618342 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.482       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | -178        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 2194        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012830116 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.843       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2331        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009391759 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 590          |\n",
      "|    ep_rew_mean          | -161         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 14           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2480         |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076525137 |\n",
      "|    clip_fraction        | 0.0893       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0298       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00774     |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | -151        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2618        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009773964 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.0482      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.306       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 0.758       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 571         |\n",
      "|    ep_rew_mean          | -142        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2770        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009339135 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | -0.0697     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.29        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    value_loss           | 0.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 570         |\n",
      "|    ep_rew_mean          | -134        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2930        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012117675 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 0.466       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO  # <--- THIS WAS MISSING\n",
    "from firecastrl_env.envs.wildfire_env import WildfireEnv\n",
    "from firecastrl_env.envs.environment import helper \n",
    "\n",
    "# --- 1. Define Wrapper (Must be re-defined if kernel was restarted) ---\n",
    "class SafeWildfireWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    def observation(self, obs):\n",
    "        if 'cells' in obs:\n",
    "            obs['cells'] = np.nan_to_num(obs['cells'], posinf=-1.0)\n",
    "        return obs\n",
    "\n",
    "class MultiAgentRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, mode=\"cooperative\"):\n",
    "        super().__init__(env)\n",
    "        self.mode = mode.lower()\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, _, terminated, truncated, info = self.env.step(action)\n",
    "        if self.mode == \"cooperative\":\n",
    "            new_reward = self._calculate_cooperative(info, obs)\n",
    "        else:\n",
    "            new_reward = self._calculate_competitive(info)\n",
    "        return obs, float(new_reward), terminated, truncated, info\n",
    "\n",
    "    def _calculate_cooperative(self, info, obs):\n",
    "        curr_burning = info['cells_burning']\n",
    "        total_extinguished = obs['quenched_cells'][0]\n",
    "        reward = 10.0 * total_extinguished\n",
    "        reward -= 0.1 * curr_burning\n",
    "        reward -= self._calculate_wasted_water_penalty()\n",
    "        return np.clip(reward, -50.0, 50.0)\n",
    "\n",
    "    def _calculate_competitive(self, info):\n",
    "        # GREEDY LOGIC: No penalty for burning cells\n",
    "        wasted_penalty = self._calculate_wasted_water_penalty()\n",
    "        total_extinguished = self.env.unwrapped.state['quenched_cells'][0]\n",
    "        reward = 10.0 * total_extinguished\n",
    "        reward -= wasted_penalty\n",
    "        return np.clip(reward, -50.0, 50.0)\n",
    "\n",
    "    def _calculate_wasted_water_penalty(self):\n",
    "        penalty = 0.0\n",
    "        base_env = self.env.unwrapped\n",
    "        for i in range(base_env.num_agents):\n",
    "            last_act = base_env.state['last_action'][i]\n",
    "            hx, hy = base_env.state['helicopter_coord'][i]\n",
    "            if last_act == 4:\n",
    "                cell_idx = helper.get_grid_index_for_location(hx, hy, base_env.gridWidth)\n",
    "                cell = base_env.cells[cell_idx]\n",
    "                if cell.fireState != 1: \n",
    "                    penalty += 2.0\n",
    "        return penalty\n",
    "\n",
    "# --- 2. Train COMPETITIVE (GREEDY) ---\n",
    "print(\"ðŸ’° Starting COMPETITIVE/GREEDY Training...\")\n",
    "raw_env = WildfireEnv(num_agents=3)\n",
    "safe_env = SafeWildfireWrapper(raw_env)\n",
    "\n",
    "# CHANGE MODE HERE\n",
    "comp_env = MultiAgentRewardWrapper(safe_env, mode=\"competitive\")\n",
    "\n",
    "model_comp = PPO(\"MultiInputPolicy\", comp_env, verbose=1)\n",
    "model_comp.learn(total_timesteps=100_000)\n",
    "model_comp.save(\"ppo_fire_squad_greedy\")\n",
    "print(\"âœ… Greedy Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a6248-64a0-46c2-a571-b1e6bfa243ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Firecast)",
   "language": "python",
   "name": "firecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
