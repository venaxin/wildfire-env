{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a3bbe7-03a2-42c5-8b10-6a96a7ebb8a7",
   "metadata": {},
   "source": [
    "## <center>CSE 546: Reinforcement Learning</center>\n",
    "### <center>Prof. Alina Vereshchaka</center>\n",
    "#### <center>Fall 2025</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466af111-28e3-4ef4-a659-e83ddd268a19",
   "metadata": {},
   "source": [
    "# Welcome to the Bonus: Firecast RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b496e4e-9b78-42d5-ae2d-3eb1ff5de208",
   "metadata": {},
   "source": [
    "## IMPORTS & SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2beacf-a153-488b-94fd-3a715c7e8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "# Adjust this import based on your folder structure, or pass the helper module if needed\n",
    "from firecastrl_env.envs.environment import helper \n",
    "\n",
    "class MultiAgentRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, mode=\"cooperative\"):\n",
    "        super().__init__(env)\n",
    "        self.mode = mode.lower()\n",
    "        if self.mode not in [\"cooperative\", \"competitive\"]:\n",
    "            raise ValueError(\"Mode must be 'cooperative' or 'competitive'\")\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Run the environment step normally\n",
    "        obs, original_reward, terminated, truncated, info = self.env.step(action)\n",
    "        \n",
    "        # Override the reward based on the selected mode\n",
    "        if self.mode == \"cooperative\":\n",
    "            new_reward = self._calculate_cooperative(info, obs)\n",
    "        else:\n",
    "            new_reward = self._calculate_competitive(info)\n",
    "            \n",
    "        return obs, float(new_reward), terminated, truncated, info\n",
    "\n",
    "    def _calculate_cooperative(self, info, obs):\n",
    "        \"\"\"\n",
    "        GLOBAL GOAL: Minimize total fire damage.\n",
    "        - High penalty for existing fire (Fear of spread).\n",
    "        - Reward for extinguishing.\n",
    "        \"\"\"\n",
    "        curr_burning = info['cells_burning']\n",
    "        total_extinguished = obs['quenched_cells'][0]\n",
    "        \n",
    "        reward = 0.0\n",
    "        # 1. Team Achievement: Extinguish fires\n",
    "        reward += 10.0 * total_extinguished\n",
    "        \n",
    "        # 2. Team Penalty: The existence of fire anywhere is bad\n",
    "        reward -= 0.1 * curr_burning  # Strong pressure to contain spread\n",
    "        \n",
    "        # 3. Wasted Water Check (Still needed so they learn to aim)\n",
    "        reward -= self._calculate_wasted_water_penalty()\n",
    "        \n",
    "        return np.clip(reward, -50.0, 50.0)\n",
    "\n",
    "    def _calculate_competitive(self, info):\n",
    "        \"\"\"\n",
    "        INDIVIDUAL/GREEDY GOAL: Maximize personal score.\n",
    "        - No penalty for fire spread (Don't care about the forest).\n",
    "        - Only care about hitting targets and not wasting ammo.\n",
    "        \"\"\"\n",
    "        # Note: For a Centralized Agent, this is the \"Sum of Greedy Objectives\"\n",
    "        reward = 0.0\n",
    "        \n",
    "        # 1. We need to recalculate extinguishing based on individual hits if possible, \n",
    "        # but since 'quenched_cells' is aggregated, we use the aggregate + strict local penalties.\n",
    "        # Ideally, we trust the env's 'quenched_cells' is the sum of valid hits.\n",
    "        \n",
    "        # We rely heavily on the 'Wasted Water' penalty to define the greedy behavior.\n",
    "        # If they hit: +10. If they miss: -2. If they ignore fire: 0 penalty (unlike cooperative).\n",
    "        \n",
    "        wasted_penalty = self._calculate_wasted_water_penalty()\n",
    "        \n",
    "        # If they didn't waste water, did they actually hit something?\n",
    "        # We infer hits from total_extinguished (which is passed in info/obs usually, but let's grab from state)\n",
    "        total_extinguished = self.env.unwrapped.state['quenched_cells'][0]\n",
    "        \n",
    "        reward += 10.0 * total_extinguished\n",
    "        reward -= wasted_penalty\n",
    "        \n",
    "        # CRITICAL DIFFERENCE: NO PENALTY for 'curr_burning'. \n",
    "        # The agent feels no pressure if the fire is growing, only pressure to get points.\n",
    "        \n",
    "        return np.clip(reward, -50.0, 50.0)\n",
    "\n",
    "    def _calculate_wasted_water_penalty(self):\n",
    "        \"\"\"Iterate through agents to find who missed.\"\"\"\n",
    "        penalty = 0.0\n",
    "        \n",
    "        # Access the internal state of the environment\n",
    "        # Note: We use env.unwrapped to bypass any other wrappers\n",
    "        base_env = self.env.unwrapped\n",
    "        \n",
    "        for i in range(base_env.num_agents):\n",
    "            last_act = base_env.state['last_action'][i]\n",
    "            hx, hy = base_env.state['helicopter_coord'][i]\n",
    "            \n",
    "            if last_act == 4: # Attempted Drop\n",
    "                # Check what is at this location\n",
    "                cell_idx = helper.get_grid_index_for_location(hx, hy, base_env.gridWidth)\n",
    "                cell = base_env.cells[cell_idx]\n",
    "                \n",
    "                # If dropping on non-burning cell -> Wasted Water\n",
    "                # Assuming FireState.Burning is 1 (Check your enums.py to be sure!)\n",
    "                if cell.fireState != 1: \n",
    "                    penalty += 2.0\n",
    "                    \n",
    "        return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee73de23-339b-4ce3-8c66-239a20c07a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 694       |\n",
      "|    ep_rew_mean     | -3.56e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 21        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 93        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 677         |\n",
      "|    ep_rew_mean          | -3.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008162169 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.82       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.31e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    value_loss           | 8.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 709         |\n",
      "|    ep_rew_mean          | -3.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009889722 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.00199     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.23e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 9.37e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 709         |\n",
      "|    ep_rew_mean          | -3.82e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011851945 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.000236    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.36e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 9.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 697         |\n",
      "|    ep_rew_mean          | -3.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016747158 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.000122    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.46e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 9.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -3.64e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009819036 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 3.84e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.35e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 9.31e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 678         |\n",
      "|    ep_rew_mean          | -3.62e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010285877 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 2.81e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+03     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 6.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 677         |\n",
      "|    ep_rew_mean          | -3.56e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010351654 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 3.09e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.52e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 7.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 672         |\n",
      "|    ep_rew_mean          | -3.53e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 930         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009919405 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 7.99e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.48e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 6.57e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 657          |\n",
      "|    ep_rew_mean          | -3.46e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1078         |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078919865 |\n",
      "|    clip_fraction        | 0.0876       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.74        |\n",
      "|    explained_variance   | 9.72e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.82e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    value_loss           | 8.42e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 657         |\n",
      "|    ep_rew_mean          | -3.43e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1177        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684606 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 4.11e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 5.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -3.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1275        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008926878 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 4.71e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.35e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    value_loss           | 8e+03       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 664         |\n",
      "|    ep_rew_mean          | -3.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1374        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009596849 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 5.48e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.52e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 4.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 672         |\n",
      "|    ep_rew_mean          | -3.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1474        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007344041 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 2.68e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.8e+03     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    value_loss           | 7.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 676         |\n",
      "|    ep_rew_mean          | -3.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1561        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013698185 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 4.63e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+03     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 6.52e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -3.43e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1652        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014729531 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 1.28e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.39e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 5.5e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 679        |\n",
      "|    ep_rew_mean          | -3.45e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 1741       |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00852869 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.68      |\n",
      "|    explained_variance   | 2.09e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.42e+03   |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00627   |\n",
      "|    value_loss           | 6.35e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 681          |\n",
      "|    ep_rew_mean          | -3.46e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 1833         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077244015 |\n",
      "|    clip_fraction        | 0.0891       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 3.34e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.88e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    value_loss           | 5.54e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 683         |\n",
      "|    ep_rew_mean          | -3.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1943        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009930831 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 1.49e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    value_loss           | 5.51e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | -3.49e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2031        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013203547 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.64       |\n",
      "|    explained_variance   | 1.55e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.88e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 6.81e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | -3.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2122        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011674228 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 9.54e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 5.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | -3.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2220        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014819171 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 2.62e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.25e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 5.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 682         |\n",
      "|    ep_rew_mean          | -3.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2318        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011619083 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 1.25e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79e+03    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    value_loss           | 6.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 687          |\n",
      "|    ep_rew_mean          | -3.47e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2451         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113655785 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.55        |\n",
      "|    explained_variance   | 8.34e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00852     |\n",
      "|    value_loss           | 4.82e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 682         |\n",
      "|    ep_rew_mean          | -3.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2615        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016572293 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 5.36e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    value_loss           | 5.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 676         |\n",
      "|    ep_rew_mean          | -3.41e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 2709        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007915152 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 5.36e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    value_loss           | 5.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -3.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 2818        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009712635 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 6.56e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    value_loss           | 4.99e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 685        |\n",
      "|    ep_rew_mean          | -3.44e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 2921       |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01100114 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.45      |\n",
      "|    explained_variance   | 3.58e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.93e+03   |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00906   |\n",
      "|    value_loss           | 4.15e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | -3.44e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3029        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014201056 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.46       |\n",
      "|    explained_variance   | 4.77e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+03     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 5.81e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | -3.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 3125        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009267174 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    value_loss           | 5.49e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 690        |\n",
      "|    ep_rew_mean          | -3.47e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 3227       |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01596675 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.44      |\n",
      "|    explained_variance   | 2.38e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.63e+03   |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    value_loss           | 4.91e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -3.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 3319        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011698232 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    value_loss           | 4.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -3.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 3410        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011173447 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 5.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | -3.49e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 3519        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016951952 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 5.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -3.49e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 3622        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010725377 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.32e+03    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    value_loss           | 4.15e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -3.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 3718        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011363737 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 2.98e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    value_loss           | 5.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 678         |\n",
      "|    ep_rew_mean          | -3.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 3824        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011402266 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 677         |\n",
      "|    ep_rew_mean          | -3.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 3922        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015069433 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.52e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    value_loss           | 5.47e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 679         |\n",
      "|    ep_rew_mean          | -3.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 4014        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010785541 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.36       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    value_loss           | 5.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 683         |\n",
      "|    ep_rew_mean          | -3.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 4112        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010728186 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 4.17e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 4.79e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -3.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 4218        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020255405 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00046    |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 678         |\n",
      "|    ep_rew_mean          | -3.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 4328        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009579298 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+03    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | -3.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 4430        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011387225 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71e+03    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    value_loss           | 5.12e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 682        |\n",
      "|    ep_rew_mean          | -3.4e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 4541       |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01651136 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.15      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.18e+03   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00996   |\n",
      "|    value_loss           | 4.11e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 675         |\n",
      "|    ep_rew_mean          | -3.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 4649        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026777413 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    value_loss           | 4.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 665         |\n",
      "|    ep_rew_mean          | -3.34e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 4748        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008481455 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.36       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.49e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 6.21e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 665        |\n",
      "|    ep_rew_mean          | -3.33e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 4849       |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03397668 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.09      |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.74e+03   |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00301   |\n",
      "|    value_loss           | 4.36e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 660         |\n",
      "|    ep_rew_mean          | -3.31e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 4951        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007915901 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    value_loss           | 4.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 651         |\n",
      "|    ep_rew_mean          | -3.27e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 5052        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022261795 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 4.94e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from firecastrl_env.envs.wildfire_env import WildfireEnv\n",
    "# from multi_agent_wrappers import MultiAgentRewardWrapper # If in separate file\n",
    "\n",
    "# 1. Init Base Env\n",
    "raw_env = WildfireEnv(num_agents=3)\n",
    "\n",
    "# 2. Apply Safety Wrapper (Fixes Infinity Bug)\n",
    "safe_env = SafeWildfireWrapper(raw_env)\n",
    "\n",
    "# 3. Apply Reward Strategy\n",
    "coop_env = MultiAgentRewardWrapper(safe_env, mode=\"cooperative\")\n",
    "\n",
    "# 4. Train\n",
    "model_coop = PPO(\"MultiInputPolicy\", coop_env, verbose=1)\n",
    "model_coop.learn(total_timesteps=100_000)\n",
    "model_coop.save(\"ppo_fire_squad_coop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e21dc-45a7-4d65-beeb-a99b5ed582c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Firecast)",
   "language": "python",
   "name": "firecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
